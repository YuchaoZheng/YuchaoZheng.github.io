---
layout:     post
title:      Alexnet实现及微调
date:       2018-10-23
author:     ZYC
header-img: img/post-bg-ios9-web.jpg
catalog: 	 true
mathjax:     true
tags:
    - deeplearning
    - Alexnet
---

# 1.论文理解


# 2.Alexnet实现
[参考文章1](https://zhuanlan.zhihu.com/p/27381582)

## 2.1 Alexnet结构

- 网络结构



- 卷积层

由于2012年，GPU性能较弱，内存不够。因此AlexNet通过两个GPU协同训练CNN，在一些层的计算我们需要先将输入以及卷积核分为两组，分别计算然后得到的feature map再合并，因此我们设置了groups参数。



- maxPooling


- lrn

$b_{x,y}^{i} = a_{x,y}^{i}/(k+\alpha \sum_{j=max(0,i-n/2)}^{min(N-1,i+n/2)}(a_{x,y}^{i})^{2})^{\beta}$
$a[batch,\ height,\ weight,\ channels]$
$N是该层的feature\ map总数，n表示取该feature\ map为中间的左右各n/2个feature\ map来求均值。$
$k,n,\alpha,\beta都是固定值,每一层ReLU后面都接一层LRN。$
$a,n/2,k,α,β分别表示函数中的input,depth_radius,bias,alpha,beta$

- fc

- 创建网络图

- load_weights

- test_image

对于输入图像，我们首先将其大小归一化为网络输入大小，并定义一个占位符用以结果输出，然后加载网络模型，正向传播网络得到FC8层输出结果，然后将softmax结果转换为类别结果。



## 2.2 tensorflow运行流程
[参考文章](https://blog.csdn.net/u014595019/article/details/52677412)



# 3.Alexnext微调


augment 增加

小数据上，物体检测已经很好了，特别是增加标签保留转换。

1. Input layer: 224 * 224 * 3 （RGB图片，224 * 224像素）
2. Conv layer: 96 kernels of 11 * 11 * 3 - Response Normalization - Max-Pooling - ReLU
3. Conv layer2: 256 kernels of 5 * 5 * 48 - Response Normalization - Max-Pooling - ReLU
4. Conv layer3: 384 kernels of 3 * 3 * 256 - ReLU
5. Conv layer4: 384 kernels of 3 * 3 * 192 - Max-Pooling - ReLU
6. Conv layer5: 256 kernels of 3 * 3 * 192 - ReLU
7. Fully-connected1 of size 4096 - ReLU
8. Fully-connected2 of size 4096 - ReLU
9. Fully-connected3 of size 4096 - ReLU
10. Softmax output 1000

>一个卷积层中除了卷积层以外还可能包含一个ReLU层, 一个Pool层, 一个Norm层


realistic 切实，实际
exhibit 表现出
variability 易变
shortcomings 缺点
immense complexity 非常复杂
compensate 补偿
assumptions 假设
statistics 统计

CNN的学习能力可以通过控制网络的深度和宽度来调整，它们也可以对图片的本质（高层属性）做出强大而且基本准确的假设（统计上的稳定性，以及像素依赖的局部性特征）

attractive 吸引力
prohibitively expensive 非常昂贵
scale 规模
paired with 配合
facilitate 促进
inferior 下，劣势

本文的主要贡献包括：我们在ImageNet的2010和2012数据集集上训练了最大的CNNs之一，并且达到了迄今为止最好的结果。我们编写了一个高度优化的2D卷积的GPU实现，以及其他所有训练CNNs的固有操作，并将其公之于众。我们的网络包含一系列新的不同凡响的特征，这提高了它的表现性能，减少了它的训练时间，具体情况在第三章介绍。
即使我们拥有120万的标签样例，我们的网络的巨大体积也使得过拟合成了一个严重的问题，所以我们需要一系列技术去克服过拟合，这将在第四章中描述。
我们的网络最终包含5个卷积层和3个全连接层，这个深度也许是很重要的：我们发现去掉任意一个卷积层都会导致更差的表现，即使每个卷积层仅包含不到1%的模型参数。


tolerate 容忍

最后，网络的大小主要被GPU中可获得的存储数量，以及可忍受训练时间所限制。
我们的网络需要在两台GTX 580 3GB GPUs训练五至六天。我们所有的实验都表明，只要等到更快的GPU和更大的数据集出现，其结果能够被进一步提高。

variable-resolution  可变分辨率
rectangular 长方形

ImageNet包含各种清晰度的图片，而我们的系统要求输入维度恒定，因此，我们对图片进行采样，获得固定大小的256X256的分辨率，对于每张长方形的图，我们将短边按比例调整为256，然后取中心区域的256X256像素。我们并未使用其他方法对图片进行预处理，除了把每个像素减去整个训练集的平均值【？？？except for subtracting the mean activity over the training set from each pixel.】所以我们的模型是在原始的RGB像素值上训练出来的。

具体做法就是对于整个训练集图片，每个通道分别减去训练集该通道平均值。

为啥要减去平均像素???

![](file:///home/yuchao/%E5%9B%BE%E7%89%87/%E9%80%89%E5%8C%BA_009.png)

饱和非线性激活函数Relu比非饱和非线性慢得多。

GTX 580 GPU：内存3G
两个GPU并行
可以直接相互访问内存信息，不用通过服务器。

dropout是指在深度学习网络的训练过程中，对于神经网络单元，按照一定的概率将其暂时从网络中丢弃。注意是暂时，对于随机梯度下降来说，由于是随机丢弃，故而每一个mini-batch都在训练不同的网络。

artificially enlarge  人工放大
augmentation  增强，放大
substantial	大量的

采取了两种不同形式的数据放大，它们都允许在仅对原图做少量计算的情况下产生变形的新图，所以变形后的新图无需存储在硬盘中。

在我们的实现中，转换的图像是在CPU上的Python代码中生成的，而GPU正在训练前一批图像。 因此，这些数据增强方案实际上在计算上是免费的。

第一种放大数据集（产生新图）的方式由图片平移和水平镜像组成，我们通过从256X256的图片中随机抽取224X224的区块（及其水平镜像）来实现这种方法，并在这些抽取后得到的区块上训练我们的神经网络。在测试过程中，网络会抽取五个（四角和中间）224 x 224的区块及其水平镜像进行预测，然后将softmax层对这十个区块做出的预测取平均。

第二种放大数据集的方法是对训练图片的RGB频谱密度进行改变。特别地，我们在整个ImageNet训练集上对RGB像素进行主成分分析(PCA)。

